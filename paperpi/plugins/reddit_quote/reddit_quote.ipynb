{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your function must import layout and constants\n",
    "# this is structured to work both in Jupyter notebook and from the command line\n",
    "try:\n",
    "    from . import layout\n",
    "    from . import constants\n",
    "except ImportError:\n",
    "    import layout\n",
    "    import constants\n",
    "\n",
    "import logging\n",
    "import re\n",
    "import json\n",
    "import secrets\n",
    "from time import time\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from os import path\n",
    "\n",
    "import requests\n",
    "from dictor import dictor\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fugly hack for making the library module available to the plugins\n",
    "sys.path.append(layout.dir_path+'/../..')\n",
    "from library import PluginTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _time_now():\n",
    "    return datetime.now().strftime(\"%H:%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fetch_quotes():\n",
    "    '''fetch quotes from reddit'''\n",
    "    error = False\n",
    "    logging.debug('fetching data from reddit')\n",
    "    raw_quotes = [constants.error_text]\n",
    "    try:\n",
    "        r = requests.get(constants.quotes_url, headers=constants.headers)\n",
    "    except requests.RequestException as e:\n",
    "        logging.error(f'failed to fetch quotes from {constants.quotes_url}, {e}')\n",
    "        return (raw_quotes, True)\n",
    "    if r.status_code == 200:\n",
    "        try:\n",
    "            json_data = dictor(r.json(), constants.quote_data_addr)\n",
    "            raw_quotes = [dictor(q, constants.quote_title_addr) for q in json_data]\n",
    "        except json.JSONDecodeError as e:\n",
    "            logging.error(f'bad json data: {e}')\n",
    "            raw_quotes = [constants.error_text]\n",
    "            error = True\n",
    "    else:\n",
    "        logging.warning(f'error accessing {constants.quotes_url}: code {r.status_code}')\n",
    "        raw_quotes = [constants.error_text]\n",
    "        error = True\n",
    "        \n",
    "    if len(raw_quotes) < 1:\n",
    "        raw_quotes = [constants.error_text]\n",
    "        error = True\n",
    "        \n",
    "    return (raw_quotes, error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _process_quotes(raw_quotes):\n",
    "    processed_quotes = []\n",
    "    logging.debug(f'processing {len(raw_quotes)} quotes')\n",
    "    for quote in raw_quotes:\n",
    "        # make sure we have a string to work with\n",
    "        quote = str(quote)\n",
    "        # sub double quotes for any other quote character or '' \n",
    "        q = re.sub('“|”|\\'\\'|\"', '', quote)\n",
    "        # sub single quote for ’ character\n",
    "        q = re.sub('’', \"'\", q)\n",
    "        # sub minus for endash, emdash, hyphen, ~\n",
    "        q = re.sub('-|–|—|~|--|―', '-', q)\n",
    "        # clean trailing whitespace in quotes\n",
    "        q = re.sub('\\s+\"', '\"', q)\n",
    "        # split quote from attirbution\n",
    "        match = re.match('(.*)\\s{0,}-\\s{0,}(.*)', q)\n",
    "\n",
    "        if hasattr(match, 'groups'):\n",
    "            if len(match.groups()) > 1:\n",
    "                text = match.group(1).strip()\n",
    "                attribution = match.group(2).strip().title()\n",
    "            else:\n",
    "                text = match.group(1).strip()\n",
    "                attribution = None\n",
    "        else:\n",
    "            text = q.strip()\n",
    "            attribution = None\n",
    "\n",
    "        # append quotes to dictionary\n",
    "        \n",
    "        processed_quotes.append({'len': len(q), 'text': text, 'attribution': attribution})\n",
    "    return processed_quotes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure this function can accept *args and **kwargs even if you don't intend to use them\n",
    "def update_function(self, *args, **kwargs):\n",
    "    '''update function for reddit_quote plugin\n",
    "    \n",
    "    Scrapes quotes from reddit.com/r/quotes and displays them one at a time\n",
    "    \n",
    "   Requirements:\n",
    "        self.config(`dict`): {\n",
    "        'max_length': 144,   # name of player to track\n",
    "        'idle_timeout': 10,               # timeout for disabling plugin\n",
    "    }\n",
    "    self.cache(`CacheFiles` object)\n",
    "\n",
    "    Args:\n",
    "        self(namespace): namespace from plugin object\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (is_updated(bool), data(dict), priority(int))   \n",
    "        \n",
    "    This plugin is inspired by and based on the veeb.ch [stonks project](https://github.com/veebch/stonks)\n",
    "    \n",
    "    %U'''  \n",
    "\n",
    "    \n",
    "    logging.info(f'update function for {constants.name}')\n",
    "    json_file = self.cache.path/Path(constants.json_file)\n",
    "    \n",
    "    max_length = self.config.get('max_length', constants.required_config_options['max_length'])\n",
    "    max_retries = self.config.get('max_retries', constants.required_config_options['max_retries'])\n",
    "    \n",
    "    try:\n",
    "        max_length = int(max_length)\n",
    "        max_retries = int(max_retries)\n",
    "    except ValueError as e:\n",
    "        logging.warning('non-numeric values provided in configuration file for max_length or max_retries')\n",
    "    \n",
    "    is_updated = False\n",
    "    data = {}\n",
    "    priority = 2**16\n",
    "    \n",
    "    logging.debug(f'checking mtime of cached json file: {json_file}')\n",
    "    \n",
    "    # check the age of the cached data\n",
    "    try:\n",
    "        mtime  = time() - path.getmtime(json_file)\n",
    "        logging.debug(f'age of {json_file}: {mtime}')\n",
    "    except OSError as e:\n",
    "#         logging.info(f'{e}')\n",
    "        mtime = 2**16\n",
    "    except json.JSONDecodeError as e:\n",
    "        logging.info(f'{e}')\n",
    "        mtime = 2**16\n",
    "        \n",
    "    \n",
    "    if json_file.exists() and mtime < constants.json_max_age:\n",
    "        try:\n",
    "            logging.debug('using cached reddit data')\n",
    "            with open(json_file) as jf:\n",
    "                json_data = json.load(jf)\n",
    "        except OSError as e:\n",
    "            logging.warning(f'could not open cached JSON file: {e}')\n",
    "        except json.JSONDecodeError as e:\n",
    "            logging.error(f'could not decode JSON file: {e}')\n",
    "            json_data = None\n",
    "    else:\n",
    "        logging.debug('cached data expired, fetching fresh data')\n",
    "        json_data = None\n",
    "            \n",
    "    \n",
    "    if not json_data:\n",
    "        logging.debug('downloading fresh data from reddit')\n",
    "        raw_quotes, fetch_error = _fetch_quotes()\n",
    "        json_data = _process_quotes(raw_quotes)\n",
    "        \n",
    "        if fetch_error:\n",
    "            logging.warning('failed to fetch data due to previous errors. skipping cache.')\n",
    "        else:\n",
    "            logging.info('caching data')\n",
    "            try:\n",
    "                with open(json_file, 'w')  as jf:\n",
    "                    json.dump(json_data, jf)\n",
    "            except OSError as e:\n",
    "                logging.error(f'failed to cache data: {e}')\n",
    "            \n",
    "    if json_data:  \n",
    "        for i in range(0, max_retries):\n",
    "            logging.debug(f'choosing quote with length < {max_length} characters')\n",
    "            my_quote = secrets.choice(json_data)\n",
    "            if my_quote['len'] < max_length:\n",
    "                break\n",
    "            else:\n",
    "                logging.debug(f'quote was too long: {my_quote[\"len\"]} characters')\n",
    "        if my_quote['attribution']:\n",
    "            attribution = my_quote['attribution']\n",
    "            my_quote['attribution'] = f'{constants.attribution_char}{attribution}'\n",
    "        logging.debug(my_quote)\n",
    "        \n",
    "        data = my_quote\n",
    "        data['time'] = _time_now()\n",
    "        data['tag_image'] = constants.tag_image\n",
    "        is_updated = True\n",
    "        priority = self.max_priority\n",
    "\n",
    "    if 'text_color' in self.config or 'bkground_color' in self.config:\n",
    "        logging.info('using user-defined colors')\n",
    "        colors = PluginTools.text_color(config=self.config, mode=self.screen_mode,\n",
    "                               default_text=self.layout.get('fill', 'WHITE'),\n",
    "                               default_bkground=self.layout.get('bkground', 'BLACK'))\n",
    "\n",
    "        text_color = colors['text_color']\n",
    "        bkground_color = colors['bkground_color']\n",
    "\n",
    "\n",
    "        # set the colors\n",
    "        logging.debug(f'trying to set fill and background for sections: {list(self.layout.keys())}')\n",
    "        for section in self.layout:\n",
    "            if self.layout[section].get('rgb_support', False):\n",
    "                logging.debug(f'setting {section} layout colors to fill: {text_color}, bkground: {bkground_color}')\n",
    "                self.layout_obj.update_block_props(section, {'fill': text_color, 'bkground': bkground_color}) \n",
    "\n",
    "            else:\n",
    "                logging.debug(f'section {section} does not support RGB colors')\n",
    "        \n",
    "        \n",
    "    return (is_updated, data, priority)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook reddit_quote.ipynb to python\n",
      "[NbConvertApp] Writing 8425 bytes to reddit_quote.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter-nbconvert --to python --template python_clean reddit_quote.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # this code snip simulates running from within the display loop use this and the following\n",
    "# # cell to test the output\n",
    "# import logging\n",
    "# logging.root.setLevel('DEBUG')\n",
    "# from library.CacheFiles import CacheFiles\n",
    "# from library.Plugin import Plugin\n",
    "# from IPython.display import display\n",
    "\n",
    "# test_plugin = Plugin(resolution=(800, 600), screen_mode='RGB')\n",
    "# test_plugin.refresh_rate = 5\n",
    "# l = layout.layout\n",
    "# # l = layout.quote\n",
    "# test_plugin.config = {\n",
    "#     'text_color': 'RED',\n",
    "#     'bkground_color': 'random'\n",
    "# }\n",
    "# test_plugin.layout = l\n",
    "# test_plugin.cache = CacheFiles()\n",
    "# test_plugin.update_function = update_function\n",
    "# test_plugin.update()\n",
    "# test_plugin.image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaperPi-VBShxqF-",
   "language": "python",
   "name": "paperpi-vbshxqf-"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
